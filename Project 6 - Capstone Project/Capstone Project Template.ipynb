{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Explore United States Immigration Data\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The Organization for Tourism Development (OTD) want to analyze migration flux in USA, in order to find insights to significantly and sustainably develop the tourism in USA. To support their core idea they have identified a set of analysis/queries they want to run on the raw data available. The project deals with building a ETL data pipeline, to go from raw data to the data insights on the migration flux.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, FloatType, TimestampType  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "##### What data \n",
    "This project using 4 datasets includes:\n",
    "* I94 immigration data for year 2016. Used for the main analysis\n",
    "* World Temperature Data\n",
    "* Airport Code Table\n",
    "* U.S. City Demographic Data\n",
    "\n",
    "##### What tools\n",
    "* Apache Hadoop: using to stored data\n",
    "* Apche Spark: using to transform and analyst data\n",
    "* Apache Aiflow: using to schedule tasks\n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "[I94 Immigration Data](https://travel.trade.gov/research/reports/i94/historical/2016.html) (SAS format): The data are provided by the US National Tourism and Trade Office. It is a collection of all I94 that have been filed in 2016.\n",
    "\n",
    "[World Temperature Data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) (CSV format): This dataset is from Kaggle and contains monthly average temperature data at different country in the world wide.\n",
    "\n",
    "[U.S. City Demographic Data](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/) (CSV format): The dataset comes from OpenSoft. It contains demographic info on US cities. The info are organized like in the picture below.\n",
    "\n",
    "[Airport Codes Data](https://datahub.io/core/airport-codes#data) (CSV format)\n",
    "This is a table of airport codes, and information on the corresponding cities, like gps coordinates, elevation, country, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read sample immigration data using pandas\n",
    "immi_df = pd.read_csv(\"immigration_data_sample.csv\").iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0      1.0   \n",
       "1  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0      1.0   \n",
       "2  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0      1.0   \n",
       "3  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0      1.0   \n",
       "4   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0      3.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      HI  20573.0   ...         NaN        M   1955.0  07202016      F   \n",
       "1      TX  20568.0   ...         NaN        M   1990.0  10222016      M   \n",
       "2      FL  20571.0   ...         NaN        M   1940.0  07052016      M   \n",
       "3      CA  20581.0   ...         NaN        M   1991.0  10272016      M   \n",
       "4      NY  20553.0   ...         NaN        M   1997.0  07042016      F   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0    NaN      JL  5.658267e+10  00782       WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG       B2  \n",
       "2    NaN      LH  5.578047e+10  00464       WT  \n",
       "3    NaN      QR  9.478970e+10  00739       B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND       WT  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 28 columns):\n",
      "cicid       1000 non-null float64\n",
      "i94yr       1000 non-null float64\n",
      "i94mon      1000 non-null float64\n",
      "i94cit      1000 non-null float64\n",
      "i94res      1000 non-null float64\n",
      "i94port     1000 non-null object\n",
      "arrdate     1000 non-null float64\n",
      "i94mode     1000 non-null float64\n",
      "i94addr     941 non-null object\n",
      "depdate     951 non-null float64\n",
      "i94bir      1000 non-null float64\n",
      "i94visa     1000 non-null float64\n",
      "count       1000 non-null float64\n",
      "dtadfile    1000 non-null int64\n",
      "visapost    382 non-null object\n",
      "occup       4 non-null object\n",
      "entdepa     1000 non-null object\n",
      "entdepd     954 non-null object\n",
      "entdepu     0 non-null float64\n",
      "matflag     954 non-null object\n",
      "biryear     1000 non-null float64\n",
      "dtaddto     1000 non-null object\n",
      "gender      859 non-null object\n",
      "insnum      35 non-null float64\n",
      "airline     967 non-null object\n",
      "admnum      1000 non-null float64\n",
      "fltno       992 non-null object\n",
      "visatype    1000 non-null object\n",
      "dtypes: float64(15), int64(1), object(12)\n",
      "memory usage: 218.8+ KB\n"
     ]
    }
   ],
   "source": [
    "immi_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read a immigration sas data file using spark\n",
    "immi_spark_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immi_spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immi_spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi_spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write spark dataframe to parquet files\n",
    "immi_spark_df.write.parquet(\"sas_data\")\n",
    "immi_spark_df=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read temperature data to dataframe\n",
    "temp_df = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "temp_df.info()\n",
    "temp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read temperature data to dataframe\n",
    "demo_df = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "demo_df.info()\n",
    "demo_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Read airport data to dataframe\n",
    "airport_df = pd.read_csv('airport-codes_csv.csv')\n",
    "airport_df.info()\n",
    "airport_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "1. Use pandas for exploratory data analysis to get an overview on these data sets (above)\n",
    "2. Use PySpark for spliting data sets to dimensional tables and change column names for better understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read immigration data file to dataframe\n",
    "immi_spark_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Change data type of some columns from double to integer\n",
    "toInt = udf(lambda x: int(x) if x!=None else x, IntegerType())\n",
    "\n",
    "for colname, coltype in immi_spark_df.dtypes:\n",
    "    if coltype == 'double':\n",
    "        immi_spark_df = immi_spark_df.withColumn(colname, toInt(colname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: integer (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: integer (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: integer (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immi_spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract columns to create fact_immigration table\n",
    "fact_immigration_df = immi_spark_df.select('cicid', 'i94port', 'i94addr', 'i94visa', 'i94yr', \\\n",
    "                                'i94mon', 'i94mode', 'arrdate', 'depdate').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename columns of fact_immigration table\n",
    "fact_immigration_df = fact_immigration_df.withColumnRenamed('i94port', 'city_code') \\\n",
    "                                .withColumnRenamed('i94addr', 'state_code') \\\n",
    "                                .withColumnRenamed('i94visa', 'visa') \\\n",
    "                                .withColumnRenamed('i94yr', 'year') \\\n",
    "                                .withColumnRenamed('i94mon', 'month') \\\n",
    "                                .withColumnRenamed('i94mode', 'mode') \\\n",
    "                                .withColumnRenamed('arrdate', 'arrive_date') \\\n",
    "                                .withColumnRenamed('depdate', 'departure_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_immigration_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop null records on state_code column\n",
    "fact_immigration_df = fact_immigration_df.where(col('state_code').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2943721"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_immigration_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add country column to fact_immigration table\n",
    "fact_immigration_df = fact_immigration_df.withColumn('country', lit('United States'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Change date type from SAS to timestamp\n",
    "@udf(TimestampType())\n",
    "def to_timestamp_udf(x):\n",
    "    try:\n",
    "        return pd.to_timedelta(x, unit='D') + pd.Timestamp('1960-1-1')\n",
    "    except:\n",
    "        return pd.Timestamp('1900-1-1')\n",
    "    \n",
    "fact_immigration_df = fact_immigration_df.withColumn('arrive_date', to_date(to_timestamp_udf(col('arrive_date')))) \\\n",
    "                                    .withColumn('departure_date', to_date(to_timestamp_udf(col('departure_date'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- visa: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- arrive_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- country: string (nullable = false)\n",
      "\n",
      "+-----+---------+----------+----+----+-----+----+-----------+--------------+-------------+\n",
      "|cicid|city_code|state_code|visa|year|month|mode|arrive_date|departure_date|      country|\n",
      "+-----+---------+----------+----+----+-----+----+-----------+--------------+-------------+\n",
      "|  814|      ATL|        GA|   1|2016|    4|   1| 2016-04-01|    2016-04-02|United States|\n",
      "| 1158|      WAS|        MD|   2|2016|    4|   1| 2016-04-01|    2016-04-03|United States|\n",
      "| 1475|      NYC|        NY|   2|2016|    4|   1| 2016-04-01|    2016-04-08|United States|\n",
      "| 1581|      LOS|        CA|   2|2016|    4|   1| 2016-04-01|    2016-04-10|United States|\n",
      "| 1676|      MIA|        FL|   2|2016|    4|   1| 2016-04-01|    2016-04-21|United States|\n",
      "+-----+---------+----------+----+----+-----+----+-----------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_immigration_df.printSchema()\n",
    "fact_immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract columns to create dim_immigrate_person\n",
    "dim_immigrate_person_df = immi_spark_df.select('cicid', 'i94cit', 'i94res',\\\n",
    "                                        'biryear', 'gender', 'insnum').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename columns of dim_immigrate_person table\n",
    "dim_immigrate_person_df = dim_immigrate_person_df.withColumnRenamed('i94cit', 'citizen_country_code') \\\n",
    "                                    .withColumnRenamed('i94res', 'citizen_state_code') \\\n",
    "                                    .withColumnRenamed('biryear', 'birth_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- citizen_country_code: integer (nullable = true)\n",
      " |-- citizen_state_code: integer (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      "\n",
      "+-----+--------------------+------------------+----------+------+------+\n",
      "|cicid|citizen_country_code|citizen_state_code|birth_year|gender|insnum|\n",
      "+-----+--------------------+------------------+----------+------+------+\n",
      "|  286|                 103|               103|      1992|     F|  null|\n",
      "|  763|                 103|               103|      1975|  null|  null|\n",
      "|  877|                 104|               104|      1975|     F|  null|\n",
      "| 1336|                 104|               104|      1961|     M|  null|\n",
      "| 2307|                 107|               107|      1961|     M|  null|\n",
      "+-----+--------------------+------------------+----------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_immigrate_person_df.printSchema()\n",
    "dim_immigrate_person_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read temperature data file to dataframe using spark\n",
    "temp_df = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filter data in United States\n",
    "temp_df = temp_df.where(temp_df['Country'] == 'United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract columns to create dim_temperature table\n",
    "dim_temperature_df = temp_df.select('dt', 'AverageTemperature', 'AverageTemperatureUncertainty', \\\n",
    "                            'City', 'Country').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename columns of dim_temperature\n",
    "dim_temperature_df = dim_temperature_df.withColumnRenamed('AverageTemperature', 'avg_temperture') \\\n",
    "                                .withColumnRenamed('AverageTemperatureUncertainty', 'avg_temp_uncertainty') \\\n",
    "                                .withColumnRenamed('City', 'city') \\\n",
    "                                .withColumnRenamed('Country', 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- avg_temperture: string (nullable = true)\n",
      " |-- avg_temp_uncertainty: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n",
      "+----------+------------------+--------------------+-------+-------------+\n",
      "|        dt|    avg_temperture|avg_temp_uncertainty|   city|      country|\n",
      "+----------+------------------+--------------------+-------+-------------+\n",
      "|1821-06-01|            25.768|               2.653|Abilene|United States|\n",
      "|1830-11-01|            13.302|               2.715|Abilene|United States|\n",
      "|1836-11-01|             8.827|  2.1719999999999997|Abilene|United States|\n",
      "|1846-07-01|28.258000000000003|  2.0069999999999997|Abilene|United States|\n",
      "|1863-04-01|            18.553|  1.1740000000000002|Abilene|United States|\n",
      "+----------+------------------+--------------------+-------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_temperature_df.printSchema()\n",
    "dim_temperature_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read demographic data to dataframe using spark\n",
    "demo_df = spark.read.format('csv').options(header=True, delimiter=';').load('us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rename columns of dim_demographic table\n",
    "dim_demographic_df  = demo_df.withColumnRenamed('City','city') \\\n",
    "                                .withColumnRenamed('State','state') \\\n",
    "                                .withColumnRenamed('Median Age','median_age') \\\n",
    "                                .withColumnRenamed('Male Population','male_population') \\\n",
    "                                .withColumnRenamed('Female Population','female_population') \\\n",
    "                                .withColumnRenamed('Total Population','total_population') \\\n",
    "                                .withColumnRenamed('Number of Veterans','number_of_veterans') \\\n",
    "                                .withColumnRenamed('Foreign-born','foreign_born') \\\n",
    "                                .withColumnRenamed('Average Household Size','avg_household_size') \\\n",
    "                                .withColumnRenamed('State Code','state_code')\\\n",
    "                                .withColumnRenamed('Race','race') \\\n",
    "                                .withColumnRenamed('Count','count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- number_of_veterans: string (nullable = true)\n",
      " |-- foreign_born: string (nullable = true)\n",
      " |-- avg_household_size: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      "\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+----------+--------------------+-----+\n",
      "|            city|        state|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|avg_household_size|state_code|                race|count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|               2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|              2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|              2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|              3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|              2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_demographic_df.printSchema()\n",
    "dim_demographic_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Change type of some columns to float\n",
    "colnames = ['median_age', 'male_population', 'female_population', 'total_population', \n",
    "            'number_of_veterans', 'foreign_born', 'avg_household_size', 'count']\n",
    "\n",
    "toFloat = udf(lambda x: float(x) if x!=None else x, FloatType())\n",
    "\n",
    "for colname in colnames:\n",
    "    dim_demographic_df = dim_demographic_df.withColumn(colname, toFloat(colname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: float (nullable = true)\n",
      " |-- male_population: float (nullable = true)\n",
      " |-- female_population: float (nullable = true)\n",
      " |-- total_population: float (nullable = true)\n",
      " |-- number_of_veterans: float (nullable = true)\n",
      " |-- foreign_born: float (nullable = true)\n",
      " |-- avg_household_size: float (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- count: float (nullable = true)\n",
      "\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+----------+--------------------+-------+\n",
      "|            city|        state|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|avg_household_size|state_code|                race|  count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+----------+--------------------+-------+\n",
      "|   Silver Spring|     Maryland|      33.8|        40601.0|          41862.0|         82463.0|            1562.0|     30908.0|               2.6|        MD|  Hispanic or Latino|25924.0|\n",
      "|          Quincy|Massachusetts|      41.0|        44129.0|          49500.0|         93629.0|            4147.0|     32935.0|              2.39|        MA|               White|58723.0|\n",
      "|          Hoover|      Alabama|      38.5|        38040.0|          46799.0|         84839.0|            4819.0|      8229.0|              2.58|        AL|               Asian| 4759.0|\n",
      "|Rancho Cucamonga|   California|      34.5|        88127.0|          87105.0|        175232.0|            5821.0|     33878.0|              3.18|        CA|Black or African-...|24437.0|\n",
      "|          Newark|   New Jersey|      34.6|       138040.0|         143873.0|        281913.0|            5829.0|     86253.0|              2.73|        NJ|               White|76402.0|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+----------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_demographic_df.printSchema()\n",
    "dim_demographic_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read airport data to dataframe using spark\n",
    "airport_df = spark.read.csv('airport-codes_csv.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert elevation_ft to type integer\n",
    "airport_df = airport_df.withColumn('elevation_ft', col('elevation_ft').cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add state_code column to join with fact table\n",
    "airport_df = airport_df.withColumn('state_code', split(col('iso_region'), '-').getItem(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      "\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+----------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|state_code|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+----------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|        PA|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|        KS|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|        AK|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|        AL|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|        AR|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_df.printSchema()\n",
    "airport_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract columns to create dim_airport table\n",
    "dim_airport_df = airport_df.select('ident', 'type', 'name', 'elevation_ft','iso_country', \\\n",
    "                                'state_code', 'municipality', 'coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "+-----+-------------+--------------------+------------+-----------+----------+------------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|iso_country|state_code|municipality|         coordinates|\n",
      "+-----+-------------+--------------------+------------+-----------+----------+------------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|         US|        PA|    Bensalem|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|         US|        KS|       Leoti|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|         US|        AK|Anchor Point|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|         US|        AL|     Harvest|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|         US|        AR|     Newport| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+-----------+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_airport_df.printSchema()\n",
    "dim_airport_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Star schema\n",
    "![diagram](concept_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "Fact Immigration:\n",
    "- Read immigration data file to dataframe\n",
    "- Change data type of some columns from double to integer\n",
    "- Extract columns to create fact_immigration table\n",
    "- Rename columns of fact_immigration table\n",
    "- Drop null records on state_code column\n",
    "- Add country column to fact_immigration table\n",
    "- Change date type from SAS to timestamp\n",
    "- Write fact_immigration table to parquet files and partition by state_code\n",
    "\n",
    "Dim Immigrate Person:\n",
    "- Extract columns to create dim_immigrate_person from immigration data\n",
    "- Rename columns of dim_immigrate_person table\n",
    "- Write dim_immigrat_person table to parquet files  \n",
    "\n",
    "Dim Temperature\n",
    "- Read temperature data file to dataframe\n",
    "- Filter data in United States\n",
    "- Extract columns to create dim_temperature table\n",
    "- Rename columns of dim_temperature\n",
    "- Extract year, month from dt column\n",
    "- Write dim_temperature to parquet files\n",
    "\n",
    "Dim Demographic\n",
    "- Read demographic data to dataframe\n",
    "- Rename columns of dim_demographic table\n",
    "- Change type of some columns to float\n",
    "- Write dim_demographic table to parquet files\n",
    "\n",
    "Dim Airport\n",
    "- Read airport data to dataframe\n",
    "- Convert elevation_ft to type integer\n",
    "- Add state_code column to join with fact table\n",
    "- Extract columns to create dim_airport table\n",
    "- Write dim_airport table to parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "fact_immigration_df = immi_spark_df.select('cicid', 'i94port', 'i94addr', 'i94visa', 'i94yr', \\\n",
    "                                'i94mon', 'i94mode', 'arrdate', 'depdate').distinct()\n",
    "fact_immigration_df = fact_immigration_df.withColumnRenamed('i94port', 'city_code') \\\n",
    "                                .withColumnRenamed('i94addr', 'state_code') \\\n",
    "                                .withColumnRenamed('i94visa', 'visa') \\\n",
    "                                .withColumnRenamed('i94yr', 'year') \\\n",
    "                                .withColumnRenamed('i94mon', 'month') \\\n",
    "                                .withColumnRenamed('i94mode', 'mode') \\\n",
    "                                .withColumnRenamed('arrdate', 'arrive_date') \\\n",
    "                                .withColumnRenamed('depdate', 'departure_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+----------+----+----+-----+----+-----------+--------------+-------------+\n",
      "|cicid|city_code|state_code|visa|year|month|mode|arrive_date|departure_date|      country|\n",
      "+-----+---------+----------+----+----+-----+----+-----------+--------------+-------------+\n",
      "|  814|      ATL|        GA|   1|2016|    4|   1| 2016-04-01|    2016-04-02|United States|\n",
      "| 1158|      WAS|        MD|   2|2016|    4|   1| 2016-04-01|    2016-04-03|United States|\n",
      "| 1475|      NYC|        NY|   2|2016|    4|   1| 2016-04-01|    2016-04-08|United States|\n",
      "| 1581|      LOS|        CA|   2|2016|    4|   1| 2016-04-01|    2016-04-10|United States|\n",
      "| 1676|      MIA|        FL|   2|2016|    4|   1| 2016-04-01|    2016-04-21|United States|\n",
      "+-----+---------+----------+----+----+-----+----+-----------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_immigration_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "dim_immigrate_person_df = immi_spark_df.select('cicid', 'i94cit', 'i94res',\\\n",
    "                                    'biryear', 'gender', 'insnum').distinct()\n",
    "dim_immigrate_person_df = dim_immigrate_person_df.withColumnRenamed('i94cit', 'citizen_country_code') \\\n",
    "                                    .withColumnRenamed('i94res', 'citizen_state_code') \\\n",
    "                                    .withColumnRenamed('biryear', 'birth_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------------+----------+------+------+\n",
      "|cicid|citizen_country_code|citizen_state_code|birth_year|gender|insnum|\n",
      "+-----+--------------------+------------------+----------+------+------+\n",
      "|  286|                 103|               103|      1992|     F|  null|\n",
      "|  763|                 103|               103|      1975|  null|  null|\n",
      "|  877|                 104|               104|      1975|     F|  null|\n",
      "| 1336|                 104|               104|      1961|     M|  null|\n",
      "| 2307|                 107|               107|      1961|     M|  null|\n",
      "+-----+--------------------+------------------+----------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_immigrate_person_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "dim_temperature_df = temp_df.select('dt', 'AverageTemperature', 'AverageTemperatureUncertainty', \\\n",
    "                            'City', 'Country').distinct()\n",
    "dim_temperature_df = dim_temperature_df.withColumnRenamed('AverageTemperature', 'avg_temperture') \\\n",
    "                                .withColumnRenamed('AverageTemperatureUncertainty', 'avg_temp_uncertainty') \\\n",
    "                                .withColumnRenamed('City', 'city') \\\n",
    "                                .withColumnRenamed('Country', 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------------------+-------+-------------+\n",
      "|        dt|    avg_temperture|avg_temp_uncertainty|   city|      country|\n",
      "+----------+------------------+--------------------+-------+-------------+\n",
      "|1821-06-01|            25.768|               2.653|Abilene|United States|\n",
      "|1830-11-01|            13.302|               2.715|Abilene|United States|\n",
      "|1836-11-01|             8.827|  2.1719999999999997|Abilene|United States|\n",
      "|1846-07-01|28.258000000000003|  2.0069999999999997|Abilene|United States|\n",
      "|1863-04-01|            18.553|  1.1740000000000002|Abilene|United States|\n",
      "+----------+------------------+--------------------+-------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_temperature_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "dim_demographic_df  = demo_df.withColumnRenamed('City','city') \\\n",
    "                                .withColumnRenamed('State','state') \\\n",
    "                                .withColumnRenamed('Median Age','median_age') \\\n",
    "                                .withColumnRenamed('Male Population','male_population') \\\n",
    "                                .withColumnRenamed('Female Population','female_population') \\\n",
    "                                .withColumnRenamed('Total Population','total_population') \\\n",
    "                                .withColumnRenamed('Number of Veterans','number_of_veterans') \\\n",
    "                                .withColumnRenamed('Foreign-born','foreign_born') \\\n",
    "                                .withColumnRenamed('Average Household Size','avg_household_size') \\\n",
    "                                .withColumnRenamed('State Code','state_code')\\\n",
    "                                .withColumnRenamed('Race','race') \\\n",
    "                                .withColumnRenamed('Count','count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+----------+--------------------+-------+\n",
      "|            city|        state|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|avg_household_size|state_code|                race|  count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+----------+--------------------+-------+\n",
      "|   Silver Spring|     Maryland|      33.8|        40601.0|          41862.0|         82463.0|            1562.0|     30908.0|               2.6|        MD|  Hispanic or Latino|25924.0|\n",
      "|          Quincy|Massachusetts|      41.0|        44129.0|          49500.0|         93629.0|            4147.0|     32935.0|              2.39|        MA|               White|58723.0|\n",
      "|          Hoover|      Alabama|      38.5|        38040.0|          46799.0|         84839.0|            4819.0|      8229.0|              2.58|        AL|               Asian| 4759.0|\n",
      "|Rancho Cucamonga|   California|      34.5|        88127.0|          87105.0|        175232.0|            5821.0|     33878.0|              3.18|        CA|Black or African-...|24437.0|\n",
      "|          Newark|   New Jersey|      34.6|       138040.0|         143873.0|        281913.0|            5829.0|     86253.0|              2.73|        NJ|               White|76402.0|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+----------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_demographic_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "airport_df = airport_df.withColumn('state_code', split(col('iso_region'), '-').getItem(1)) \n",
    "dim_airport_df = airport_df.select('ident', 'type', 'name', 'elevation_ft','iso_country', \\\n",
    "                            'state_code', 'municipality', 'coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+-----------+----------+------------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|iso_country|state_code|municipality|         coordinates|\n",
      "+-----+-------------+--------------------+------------+-----------+----------+------------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|         US|        PA|    Bensalem|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|         US|        KS|       Leoti|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|         US|        AK|Anchor Point|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|         US|        AL|     Harvest|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|         US|        AR|     Newport| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+-----------+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_airport_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create view for quality check\n",
    "fact_immigration_df.createOrReplaceTempView('fact_immigration')\n",
    "dim_immigrate_person_df.createOrReplaceTempView('dim_immigrate_person')\n",
    "dim_temperature_df.createOrReplaceTempView('dim_temperature')\n",
    "dim_demographic_df.createOrReplaceTempView('dim_demographic')\n",
    "dim_airport_df.createOrReplaceTempView('dim_airport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data quality on table fact_immigration...\n",
      "Table fact_immigration passed. 2943721 records\n",
      "Checking data quality on table dim_immigrate_person...\n",
      "Table dim_immigrate_person passed. 3096313 records\n",
      "Checking data quality on table dim_temperature...\n",
      "Table dim_temperature passed. 687004 records\n",
      "Checking data quality on table dim_demographic...\n",
      "Table dim_demographic passed. 2891 records\n",
      "Checking data quality on table dim_airport...\n",
      "Table dim_airport passed. 55075 records\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check 01\n",
    "tables = ['fact_immigration', 'dim_immigrate_person', 'dim_temperature', 'dim_demographic', 'dim_airport']\n",
    "\n",
    "for table in tables:\n",
    "    print(f'Checking data quality on table {table}...')\n",
    "    result = spark.sql(f'''SELECT COUNT(*) FROM {table}''')\n",
    "    if result.head()[0] > 0:\n",
    "        print(f'Table {table} passed. {result.head()[0]} records')\n",
    "    else:\n",
    "        print(f'Table {table}. Data quality check failed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data quality on table fact_immigration...\n",
      "Table fact_immigration check passed\n",
      "Checking data quality on table dim_demographic...\n",
      "Table dim_demographic check passed\n",
      "Checking data quality on table dim_airport...\n",
      "Table dim_airport check passed\n",
      "Checking data quality on table dim_temperature...\n",
      "Table dim_airport check passed\n",
      "Checking data quality on table dim_immigrate_person...\n",
      "Table dim_immigrate_person check passed\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check 02\n",
    "tables = ['fact_immigration', 'dim_demographic', 'dim_airport']\n",
    "\n",
    "for table in tables:\n",
    "    print(f\"Checking data quality on table {table}...\")\n",
    "    expected_result = spark.sql(f\"\"\"SELECT COUNT(*) FROM {table} WHERE state_code IS NULL\"\"\")\n",
    "    if expected_result.head()[0] > 0:\n",
    "        print(f\"Table {table}.  Data quality check failed! Found NULL state_code values in {table} table!\")\n",
    "    else:\n",
    "        print(f\"Table {table} check passed\")\n",
    "\n",
    "# For dim_immigrate_person and dim_temperature data quality check\n",
    "print(f\"Checking data quality on table dim_temperature...\")\n",
    "expected_result = spark.sql(f\"\"\"SELECT COUNT(*) FROM dim_temperature WHERE city = 'NY'\"\"\")\n",
    "if expected_result.head()[0] < 0:\n",
    "    print(f\"Table {table}.  Data quality check failed! Cannot found NY city in dim_temperature table!\")\n",
    "else:\n",
    "    print(f\"Table {table} check passed\")\n",
    "    \n",
    "print(f\"Checking data quality on table dim_immigrate_person...\")\n",
    "expected_result = spark.sql(f\"\"\"SELECT COUNT(*) FROM dim_immigrate_person WHERE citizen_state_code IS NULL\"\"\")\n",
    "if expected_result.head()[0] > 0:\n",
    "    print(f\"Table dim_immigrate_person.  Data quality check failed! Found NULL citizen_state_code in dim_immigrate_person!\")\n",
    "else:\n",
    "    print(f\"Table dim_immigrate_person check passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-112-e49895fd66bb>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-112-e49895fd66bb>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    |-- city: string (nullable = true)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "fact_immigration\n",
    " |-- cicid: integer (nullable = true)\n",
    " |-- city_code: string (nullable = true)\n",
    " |-- state_code: string (nullable = true)\n",
    " |-- visa: integer (nullable = true)\n",
    " |-- year: integer (nullable = true)\n",
    " |-- month: integer (nullable = true)\n",
    " |-- mode: integer (nullable = true)\n",
    " |-- arrive_date: date (nullable = true)\n",
    " |-- departure_date: date (nullable = true)\n",
    " |-- country: string (nullable = false)\n",
    "\n",
    "dim_immigrate_person\n",
    " |-- cicid: integer (nullable = true)\n",
    " |-- citizen_country_code: integer (nullable = true)\n",
    " |-- citizen_state_code: integer (nullable = true)\n",
    " |-- birth_year: integer (nullable = true)\n",
    " |-- gender: string (nullable = true)\n",
    " |-- insnum: string (nullable = true)\n",
    "\n",
    "dim_temperature\n",
    " |-- dt: string (nullable = true)\n",
    " |-- avg_temperture: string (nullable = true)\n",
    " |-- avg_temp_uncertainty: string (nullable = true)\n",
    " |-- city: string (nullable = true)\n",
    " |-- country: string (nullable = true)\n",
    "\n",
    "dim_demographic\n",
    " |-- city: string (nullable = true)\n",
    " |-- state: string (nullable = true)\n",
    " |-- median_age: float (nullable = true)\n",
    " |-- male_population: float (nullable = true)\n",
    " |-- female_population: float (nullable = true)\n",
    " |-- total_population: float (nullable = true)\n",
    " |-- number_of_veterans: float (nullable = true)\n",
    " |-- foreign_born: float (nullable = true)\n",
    " |-- avg_household_size: float (nullable = true)\n",
    " |-- state_code: string (nullable = true)\n",
    " |-- race: string (nullable = true)\n",
    " |-- count: float (nullable = true)\n",
    "\n",
    "\n",
    "dim_airport\n",
    " |-- ident: string (nullable = true)\n",
    " |-- type: string (nullable = true)\n",
    " |-- name: string (nullable = true)\n",
    " |-- elevation_ft: integer (nullable = true)\n",
    " |-- iso_country: string (nullable = true)\n",
    " |-- state_code: string (nullable = true)\n",
    " |-- municipality: string (nullable = true)\n",
    " |-- coordinates: string (nullable = true) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "    - Apache Spark:\n",
    "        + Speed\n",
    "        + Ease of Use\n",
    "        + Advanced Analytics\n",
    "        + Dynamic in Nature\n",
    "        + Multilingual\n",
    "        + Apache Spark is powerful\n",
    "        + Increased access to Big data\n",
    "        + Open-source community\n",
    "    - Apache Airflow:\n",
    "        + Ease of use\n",
    "        + Integrations\n",
    "        + Coding with standard Python\n",
    "        + Graphical UI\n",
    "* Propose how often the data should be updated and why.\n",
    "    - Data should be updated monthly because the Immigration data is updated monthly\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "     - In the local machine, we can use the Spark cluster and Hadoop to scale \n",
    "     - Or we can migarte the data into the cloud like AWS with ERM cluster and S3\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "     - Using Apache Airflow is one of the best solution to schedule the data pipeline\n",
    " * The database needed to be accessed by 100+ people.\n",
    "     - AWS Redshift can handle up to 500 connections and we totaly use the Redshift database for a lot of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###  Some sample questions and sample queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "What city registered the highest number of arrivals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|city_code| count|\n",
      "+---------+------+\n",
      "|      NYC|474904|\n",
      "|      MIA|329385|\n",
      "|      LOS|292243|\n",
      "|      SFR|148637|\n",
      "|      ORL|144693|\n",
      "|      HHW|137100|\n",
      "|      NEW|133376|\n",
      "|      CHI|126139|\n",
      "|      HOU| 95736|\n",
      "|      FTL| 91756|\n",
      "+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_immigration_df.groupBy('city_code').count().sort(col('count').desc()).persist().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The gender distribution of the applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|gender|  count|\n",
      "+------+-------+\n",
      "|     F|1302743|\n",
      "|  null| 414269|\n",
      "|     M|1377224|\n",
      "|     U|    467|\n",
      "|     X|   1610|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_immigrate_person_df.select(\"gender\").groupBy(\"gender\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "What city has the most population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+\n",
      "|        city|max(total_population)|\n",
      "+------------+---------------------+\n",
      "|    New York|            8550405.0|\n",
      "| Los Angeles|            3971896.0|\n",
      "|     Chicago|            2720556.0|\n",
      "|     Houston|            2298628.0|\n",
      "|Philadelphia|            1567442.0|\n",
      "+------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_demographic_df.groupBy('city').max('total_population').orderBy(col('max(total_population)').desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "What state has the most veterans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+\n",
      "|     state|sum(number_of_veterans)|\n",
      "+----------+-----------------------+\n",
      "|California|              4617022.0|\n",
      "|     Texas|              3429512.0|\n",
      "|   Florida|              1861951.0|\n",
      "|   Arizona|              1322525.0|\n",
      "|  Virginia|              1148830.0|\n",
      "+----------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_demographic_df.groupBy('state').sum('number_of_veterans').orderBy(col('sum(number_of_veterans)').desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "What is the max and min average temperature in US?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|max(avg_temperture)|\n",
      "+-------------------+\n",
      "|              9.999|\n",
      "+-------------------+\n",
      "\n",
      "+--------------------+\n",
      "| min(avg_temperture)|\n",
      "+--------------------+\n",
      "|-0.00099999999999989|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_temperature_df.select(max('avg_temperture')).show()\n",
    "dim_temperature_df.select(min('avg_temperture')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          type|count|\n",
      "+--------------+-----+\n",
      "| large_airport|  627|\n",
      "|   balloonport|   24|\n",
      "| seaplane_base| 1016|\n",
      "|      heliport|11287|\n",
      "|        closed| 3606|\n",
      "|medium_airport| 4550|\n",
      "| small_airport|33965|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of airports by each type\n",
    "dim_airport_df.groupBy(\"type\").count().distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
